---
title: "Lab 8 - Pt. Pattern"
author: "Lucas Boyd"
date: "2/24/2022"
output: html_document
---

See: - CRS & proj4 components breakdown: https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/reproject-vector-data/

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE, message = FALSE)
library(spatstat)
library(maptools) 
library(raster) ### BEFORE tidyverse! b/c select()
library(tidyverse)
library(here)
library(sf)
library(tmap)
```


This is an example of point pattern analysis with a density plot, and the G- & L- function (distance methods) to compare our observed points with simulated complete spatial randomness.

```{r}
# Read in the tree vole data
voles <- read_sf(dsn = here("redtreevoledata"), 
                 layer = "ds033") %>% 
  janitor::clean_names() %>%
  select(county) %>% # Only select the county attribute
  filter(county == "HUM") %>% # Only keep observations in Humboldt County
  st_transform(crs = 32610) # Update CRS to UTM zone 10 N

# Plot it (exploratory)
plot(voles)
 
# Get Humboldt County outline
humboldt <- read_sf(dsn = here("redtreevoledata"), 
                    layer = "california_county_shape_file") %>% 
  janitor::clean_names() %>%
  filter(name == "Humboldt") %>% # Isolate Humboldt County
  select(name) %>% # Only keep one attribute (name) to simplify
  st_set_crs(4326) %>% # have to set this before you st_transform, look in the metadata to find it
  st_transform(crs = 32610)
# if there is no .prj file in the folder, there won't be a CRS

# plot them together
ggplot() +
  geom_sf(data = humboldt, 
          color = "darkorchid", 
          fill = "darkorchid4", 
          size = 1) + # the size of the borders of the polygon
  geom_sf(data = voles, 
          color = "orange", 
          alpha = 0.7, 
          size = 2) +
  theme_minimal()
```

These need to be combined into spatial point pattern data (points + window combo), and for point pattern analysis this **requires a 2D projection** (in this case, UTM), which is why we set the CRS to 32610 above. This looks quite a bit different from what we've done so far - it uses functions in `spatstat` to create point patterns that play nicely with other functions for data viz & point pattern analysis.

```{r}
voles_sp  <- as(voles,"Spatial") # Convert to object 'Spatial'
voles_ppp <- as(voles_sp, "ppp") # Convert to spatial point pattern
 
humboldt_sp  <- as(humboldt, "Spatial") # Convert to object 'Spatial'
humboldt_win <- as(humboldt_sp, "owin") # Convert to spatial point pattern from spatstat
 
# Combine as a point pattern object (points + window):
voles_full <- ppp(voles_ppp$x, voles_ppp$y, window = humboldt_win)

plot(voles_full) # Illegal point (outside window) shows up as the plus sign
```

## Make a kernel density plot:

### Density

Run to see vole "hotspots" by kernel density, then see what happens when you change sigma here!

```{r}
voles_density <- density(voles_full, sigma = 5000) 
# giving each one of these points a probability distributiona around it - sorta like a spatial confidence interval
# sigma is basically the standard dev 
# choose this 
plot(voles_density)
```

Pretty clear that there are "hotspots" where voles are observed - both in the originally plotted data and in the density plot. How can we compare this to complete spatial randomness? 

```{r}
# Can you start viewing this in tmap? Yes, rasterize it: 
vole_raster <- raster(voles_density)
crs(vole_raster) <- crs(voles)
 
# Then plot: 
tmap_mode("view")
 
tm_shape(vole_raster) +
  tm_raster(midpoint = NA, 
            palette = "Reds", 
            legend.show = FALSE)
```

## Nearest neighbor (G-function)

In last week's lecture, we learned about distance methods to compare our point pattern to a scenario of complete spatial randomness. Here, we'll use both the G- and L-functions (L function is the K-function, standardized...interpretation is the same) to compare our observed point pattern to a simulated CSR scenario, to help us determine if it is *more clustered* or *more uniform* than CSR.

What is going on in this code? 

- `r`: a sequence of distances (in the spatial units of the data) over which we'll calculate the proportion of points with nearest neighbor within that range

- `gfunction`: This uses the `envelope()` function within which we run simulations for CSR, *and* calculate the G-function value at distances *r* for each simulation. So this will calculate the G-function for *our* actual data, and also for simulations of CSR if we had the same number of observations in the window but they were independent. The `nsim = 100` here means there will be 100 simulations of CSR. The `nrank = 2` means that the second highest and second lowest values from simulations are shown as the "hi" and "lo" value envelopes, with the "theo" being the "theoretical value of the summary function under CSR (Complete Spatial Randomness, a uniform Poisson point process) if the simulations were generated according to CSR." So we're really comparing our "observed" data to the "theoretical CSR" here, and those "hi" and "lo" envelope bounds give us an idea of spread for the simulations. 
 
```{r}
r_vec <- seq(0, 10000, by = 100) # Make a sequence of distances over which you'll calculate G(r)
 # by = is the interval that you increase the radius from each point by (ie how many within 100 meters? 200 meters?)
gfunction <- envelope(voles_full, fun = Gest, r = r_vec, nsim = 100, nrank = 2) # Calculate the actual and theoretical G(r) values, using 100 simulations of CRS for the "theoretical" outcome
 
gfunction # << Check the output of gfunction, then...
# lo and hi are basically just bounds of a confidence interval

# Gather this to plot series in ggplot:
gfunction_long <- gfunction %>% 
  as.data.frame() %>% 
  pivot_longer(cols = obs:hi, names_to = "model", values_to = "g_val")
 
# Then make a graph in ggplot:
ggplot(data = gfunction_long, 
       aes(x = r, y = g_val, group = model)) +
  geom_line(aes(color = model))
```
green and red are bounds of confidence for CSR, purple is theoretical CSR. The blue line (actual observations) are above this, indicating clusters.

This again confirms clustering - our data (model = obs) has a greater proportion of events with nearest neighbor at *smaller distances* compared to a theoretical CSR scenario (model = theo). But remember, the G-function only considers the single nearest neighbor. 


#### L Function
Let's similarly look at the L-function (standardized K-function) which considers densities of observations within some distance R (expanding circles around each point) for comparison. This is using very similar code, but now the function is `Lest` for "L estimate", which calculates the density of events within growing circles around *each point*. That is much more intensive than just the single nearest neighbor, so I run `nsim = 10` here instead (you can do 100 or more again, you'll just notice that creating the simulations takes longer).

```{r}
r_vec2 <- seq(0, 100000, by = 5000)
 
lfunction <- envelope(voles_full, fun = Lest, r = r_vec2, nsim = 10, rank = 2, global = TRUE)
 
# Gather this to plot series in ggplot:
lfunction_long <- lfunction %>% 
  as.data.frame() %>% 
  pivot_longer(cols = obs:hi, names_to = "model", values_to = "k_val")
 
ggplot(data = lfunction_long, aes(x = r, y = k_val, group = model)) +
  geom_line(aes(color = model))
```

We again see that at lower distances, our data overall has a higher density of nearest neighbors compared to a simulated CSR scenario. Again, evidence of clustering. 

## End Lab 8 part 1
